<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Blog Reading:LLM Powered Autonomous Agents -Lilian Weng</title>
    <link href="/2025/09/20/Blog-Reading-LLM-Powered-Autonomous-Agents-Lilian-Weng/"/>
    <url>/2025/09/20/Blog-Reading-LLM-Powered-Autonomous-Agents-Lilian-Weng/</url>
    
    <content type="html"><![CDATA[<p>该博文深入探讨了以<strong>大型语言模型（LLM）为核心控制器</strong>来构建<strong>自主智能代理（Autonomous Agents）</strong> 的概念、架构、组件、案例研究及其面临的挑战。文章指出，LLM的潜力远不止于生成文本，更可被视为一个强大的通用问题解决器，作为代理的“大脑”。</p><h3 id="核心架构概述"><a href="#核心架构概述" class="headerlink" title="核心架构概述"></a>核心架构概述</h3><p>一个LLM驱动的自主代理系统通常由三个关键组件协同工作：</p><ol><li><strong>规划（Planning）</strong>：代理的核心思维能力，用于分解任务和反思改进。</li><li><strong>记忆（Memory）</strong>：代理的存储系统，用于保留和召回信息。</li><li><strong>工具使用（Tool Use）</strong>：代理与外部世界交互的手段，扩展其内在能力。</li></ol><h3 id="组件一：规划-Planning"><a href="#组件一：规划-Planning" class="headerlink" title="组件一：规划 (Planning)"></a>组件一：规划 (Planning)</h3><p>规划使代理能够处理复杂任务，主要包括两个方面：</p><p><strong>1. 任务分解 (Task Decomposition)</strong></p><ul><li><strong>思维链（CoT）</strong>：标准技术，通过“一步一步思考”的提示，将复杂任务分解为更小、更简单的步骤。</li><li><strong>思维树（ToT）</strong>：CoT的扩展，在每一步探索多种推理可能性，形成树状结构，并通过广度优先搜索（BFS）或深度优先搜索（DFS）进行搜索，由分类器（通过提示）或多数投票评估状态。</li><li><strong>分解方法</strong>：可通过LLM简单提示、任务特定指令或人类输入完成。</li><li><strong>LLM+P</strong>：一种独特方法，将长期规划外包给<strong>外部经典规划器</strong>。LLM负责将问题转换为规划域定义语言（PDDL）， classical planner生成计划，LLM再将计划转换回自然语言。该方法依赖于现成的领域PDDL和规划器。</li></ul><p><strong>2. 自我反思 (Self-Reflection)</strong><br>自我反思使代理能够从错误中学习，迭代改进其行动和策略。</p><ul><li><strong>ReAct（Reason + Act）</strong>：将<strong>推理</strong>（生成自然语言思考轨迹）和<strong>行动</strong>（调用特定任务API）结合在一个框架内。其提示模板格式为：<code>Thought: ... Action: ... Observation: ...</code>。研究表明，ReAct在知识密集和决策任务上均优于仅行动的基线。</li><li><strong>Reflexion</strong>：一个为代理配备动态记忆和自我反思能力的框架，其灵感来自强化学习（RL）设置。它引入了一种<strong>启发式函数</strong>来检测低效规划或幻觉（连续相同动作导致相同观察），并决定何时停止当前轨迹并重置环境。通过<strong>少样本示例</strong>让LLM生成自我反思，并将这些反思存入工作记忆中以指导未来规划。</li><li>** hindsight（CoH）<strong>：通过向模型展示一个</strong>带有反馈的过去输出序列**（按奖励排序）进行监督微调，训练模型根据反馈历史趋势生成更好的输出。</li><li><strong>算法蒸馏（AD）</strong>：将CoH思想应用于强化学习。它将<strong>跨 episode 的学习历史</strong>串联起来作为模型的输入，目的是让模型学会<strong>强化学习过程本身</strong>，从而在上下文中表现出学习行为，其性能接近在线RL方法。</li></ul><h3 id="组件二：记忆-Memory"><a href="#组件二：记忆-Memory" class="headerlink" title="组件二：记忆 (Memory)"></a>组件二：记忆 (Memory)</h3><p>记忆使代理能够积累和利用过去的信息。</p><ul><li><strong>记忆类型</strong>（类比人类记忆）：<ul><li><strong>感官记忆</strong>：类比于对原始输入（文本、图像等）学习嵌入表示。</li><li><strong>短期记忆</strong>：类比于<strong>上下文学习</strong>。受Transformer上下文窗口长度限制，容量有限。</li><li><strong>长期记忆</strong>：类比于<strong>外部向量存储</strong>（Vector Store），通过快速检索访问，提供近乎无限的存储容量。</li></ul></li><li><strong>最大内积搜索（MIPS）</strong>：为了快速从向量库中检索信息，常使用<strong>近似最近邻（ANN）</strong> 算法。文章介绍了几种常见算法：<ul><li><strong>LSH</strong>（局部敏感哈希）</li><li><strong>ANNOY</strong>（基于随机投影树）</li><li><strong>HNSW</strong>（分层可导航小世界图）</li><li><strong>FAISS</strong>（基于向量量化）</li><li><strong>ScaNN</strong>（各向异性向量量化）</li></ul></li></ul><h3 id="组件三：工具使用-Tool-Use"><a href="#组件三：工具使用-Tool-Use" class="headerlink" title="组件三：工具使用 (Tool Use)"></a>组件三：工具使用 (Tool Use)</h3><p>工具使用极大地扩展了LLM的能力边界，使其能够获取实时信息、执行代码等。</p><ul><li><strong>MRKL</strong>：一种神经符号架构，LLM作为<strong>路由器</strong>，将问题路由到最适合的<strong>专家模块</strong>（可以是神经或符号工具，如计算器、API）。关键在于LLM能否可靠地决定<strong>何时</strong>及<strong>如何</strong>使用工具。</li><li><strong>TALM &amp; Toolformer</strong>：通过微调LLM来学习调用外部工具API。数据集通过判断添加API调用是否能改进输出质量来构建。</li><li><strong>实践案例</strong>：ChatGPT Plugins 和 OpenAI API function calling 是工具增强LLM的实际例子。</li><li><strong>HuggingGPT</strong>：一个框架，利用ChatGPT作为<strong>任务规划器</strong>，根据模型描述选择HuggingFace平台上的模型，并总结执行结果。其工作流程分为四个阶段：<ol><li><strong>任务规划</strong>：LLM解析用户请求为多个任务。</li><li><strong>模型选择</strong>：LLM将任务分配给专家模型。</li><li><strong>任务执行</strong>：专家模型执行任务。</li><li><strong>响应生成</strong>：LLM汇总结果返回给用户。</li></ol></li><li><strong>API-Bank</strong>：一个用于评估工具增强LLM性能的基准测试，包含53个API工具和264个对话。它在三个层次上评估代理：<ul><li><strong>Level-1</strong>：调用给定API的能力。</li><li><strong>Level-2</strong>：检索正确API的能力。</li><li><strong>Level-3</strong>：超越检索和调用的规划能力（处理模糊用户请求，需多次API调用）。</li></ul></li></ul><h3 id="案例研究-Case-Studies"><a href="#案例研究-Case-Studies" class="headerlink" title="案例研究 (Case Studies)"></a>案例研究 (Case Studies)</h3><ol><li><p><strong>科学发现代理</strong>：</p><ul><li><strong>ChemCrow</strong>：一个用于化学领域（有机合成、药物发现等）的代理，集成了13个专家设计的工具。使用ReAct和MRKL模式。<strong>关键发现</strong>：人类专家评估发现ChemCrow远优于GPT-4，突显了LLM在专业领域自我评估的局限性。</li><li><strong>Boiko et al.</strong>：探索LLM代理自主设计、规划和执行复杂科学实验，使用互联网浏览、文档阅读、代码执行、机器人实验API等工具。同时讨论了其用于合成化学武器等风险。</li></ul></li><li><p><strong>生成式代理模拟</strong>：</p><ul><li><strong>Generative Agents</strong>：一个有趣的实验，25个由LLM驱动的虚拟角色在一个沙盒环境中生活互动（类似《模拟人生》）。代理架构结合了：<ul><li><strong>记忆流</strong>：记录代理经验的外部数据库。</li><li><strong>检索模型</strong>：根据<strong>相关性、新近性和重要性</strong>从记忆流中检索信息。</li><li><strong>反思机制</strong>：将记忆合成为更高层次的推断，指导未来行为。</li><li><strong>规划与反应</strong>：将反射和环境信息转化为行动。</li></ul></li><li>结果涌现出信息传播、关系记忆和社交事件协调等<strong>逼真的社会行为</strong>。</li></ul></li><li><p><strong>概念验证示例</strong>：</p><ul><li><strong>AutoGPT</strong>：一个著名的PoC演示，展示了自主代理的潜力。其系统提示定义了目标、约束、可用命令（如谷歌搜索、读写文件、执行代码等），并要求以特定JSON格式响应。大量代码用于解析自然语言输出。</li><li><strong>GPT-Engineer</strong>：根据自然语言任务描述生成整个代码库。其工作流程包括：首先要求LLM<strong>澄清任务细节</strong>，然后进入<strong>代码生成模式</strong>（使用详细的系统提示，要求生成完整、可运行、跨文件兼容的代码）。</li></ul></li></ol><h3 id="挑战-Challenges"><a href="#挑战-Challenges" class="headerlink" title="挑战 (Challenges)"></a>挑战 (Challenges)</h3><p>文章最后指出了构建LLM驱动代理面临的主要挑战：</p><ol><li><strong>有限的上下文长度</strong>：限制了历史信息、详细指令和API上下文的包含。虽然向量存储提供了扩展，但其表示能力不如全注意力机制。</li><li><strong>长期规划与任务分解的困难</strong>：LLM在根据意外错误调整计划方面存在困难，其稳健性不如人类。</li><li><strong>自然语言接口的可靠性</strong>：LLM的输出可能存在格式错误或偶尔拒绝指令，导致系统需要大量代码来解析输出，可靠性成为问题。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这篇博文全面综述了LLM驱动自主代理的技术蓝图，将其分解为规划、记忆和使用工具三大核心模块，并辅以丰富的技术细节（如ReAct、Reflexion、HNSW、HuggingGPT等）和生动案例（ChemCrow, Generative Agents, AutoGPT）。最后，它客观地指出了当前技术在实际应用中面临的上下文限制、规划可靠性和接口稳定性等关键挑战，为读者提供了对该领域深入且系统的理解。</p>]]></content>
    
    
    <categories>
      
      <category>Blog Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Agent</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计算机网络笔记</title>
    <link href="/2025/09/07/test/"/>
    <url>/2025/09/07/test/</url>
    
    <content type="html"><![CDATA[<h1 id="test"><a href="#test" class="headerlink" title="test"></a>test</h1><h2 id="test-test"><a href="#test-test" class="headerlink" title="test test"></a>test test</h2><h3 id="test-test-test"><a href="#test-test-test" class="headerlink" title="test test test"></a>test test test</h3><h3 id="another-test"><a href="#another-test" class="headerlink" title="another test"></a>another test</h3><h4 id="test-test-test-test"><a href="#test-test-test-test" class="headerlink" title="test test test test"></a>test test test test</h4>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/09/07/hello-world/"/>
    <url>/2025/09/07/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
